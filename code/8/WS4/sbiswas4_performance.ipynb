{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 4 - Performance Metrics\n",
    "\n",
    "In this workshop we study 2 performance metrics(Spread and Inter-Generational Distance) on GA optimizing the POM3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# All the imports\n",
    "from __future__ import print_function, division\n",
    "import pom3_ga, sys\n",
    "import pickle\n",
    "\n",
    "# TODO 1: Enter your unity ID here \n",
    "__author__ = \"<sbiswas4>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute most measures, data(i.e objectives) is normalized. Normalization is scaling the data between 0 and 1. Why do we normalize?\n",
    "\n",
    "TODO2 : So that no single entity,objective has undue advantage over the others just based on its unit. If the different objectives are standardized they're brought to a level playing field to be compared easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(problem, points):\n",
    "  \"\"\"\n",
    "  Normalize all the objectives\n",
    "  in each point and return them\n",
    "  \"\"\"\n",
    "  meta = problem.objectives\n",
    "  all_objs = []\n",
    "  for point in points:\n",
    "    objs = []\n",
    "    for i, o in enumerate(problem.evaluate(point)):\n",
    "      low, high = meta[i].low, meta[i].high\n",
    "      # TODO 3: Normalize 'o' between 'low' and 'high'; Then add the normalized value to 'objs'\n",
    "      if high==low: \n",
    "        objs.append(0)\n",
    "        continue\n",
    "      else:\n",
    "        objs.append((o - low)/(high-low))        \n",
    "    all_objs.append(objs)\n",
    "  return all_objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Format\n",
    "For our experiments we store the data in the following format.\n",
    "```\n",
    "data = {\n",
    "            \"expt1\":[repeat1, repeat2, ...], \n",
    "            \"expt2\":[repeat1, repeat2, ...], \n",
    "            .\n",
    "            .\n",
    "            .\n",
    "       }\n",
    "repeatx = [objs1, objs2, ....]     // All of the final population\n",
    "objs1 = [norm_obj1, norm_obj2, ...] // Normalized objectives of each member of the final population.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performing experiments for [5, 10, 50] generations.\n",
    "\"\"\"\n",
    "problem = pom3_ga.POM3()\n",
    "pop_size = 10\n",
    "repeats = 10\n",
    "test_gens = [5, 10, 50]\n",
    "\n",
    "def save_data(file_name, data):\n",
    "  \"\"\"\n",
    "  Save 'data' to 'file_name.pkl'\n",
    "  \"\"\"\n",
    "  with open(file_name + \".pkl\", 'wb') as f:\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def load_data(file_name):\n",
    "  \"\"\"\n",
    "  Retrieve data from 'file_name.pkl'\n",
    "  \"\"\"\n",
    "  with open(file_name + \".pkl\", 'rb') as f:\n",
    "    return pickle.load(f)\n",
    "\n",
    "def build(problem, pop_size, repeats, test_gens):\n",
    "  \"\"\"\n",
    "  Repeat the experiment for 'repeats' number of repeats for each value in 'test_gens'\n",
    "  \"\"\"\n",
    "  tests = {t: [] for t in test_gens}\n",
    "  tests[0] = [] # For Initial Population\n",
    "  for _ in range(repeats):\n",
    "    init_population = pom3_ga.populate(problem, pop_size)\n",
    "    pom3_ga.say(\".\")\n",
    "    for gens in test_gens:\n",
    "      tests[gens].append(normalize(problem, pom3_ga.ga(problem, init_population, retain_size=pop_size, gens=gens)[1]))\n",
    "    tests[0].append(normalize(problem, init_population))\n",
    "  print(\"\\nCompleted\")\n",
    "  return tests\n",
    "\n",
    "\"\"\"\n",
    "Repeat Experiments\n",
    "\"\"\"\n",
    "# tests = build(problem, pop_size, repeats, test_gens)\n",
    "\n",
    "\"\"\"\n",
    "Save Experiment Data into a file\n",
    "\"\"\"\n",
    "# save_data(\"dump\", tests)\n",
    "\n",
    "\"\"\"\n",
    "Load the experimented data from dump.\n",
    "\"\"\"\n",
    "tests = load_data(\"dump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference Set\n",
    "Almost all the traditional measures you consider need a reference set for its computation. A theoritical reference set would be the ideal pareto frontier. This is fine for \n",
    "a) Mathematical Models: Where we can solve the problem to obtain the set.\n",
    "b) Low Runtime Models: Where we can do a one time exaustive run to obtain the model.\n",
    "\n",
    "But most real world problems are neither mathematical nor have a low runtime. So what do we do?. **Compute an approximate reference set**\n",
    "\n",
    "One possible way of constructing it is:\n",
    "1. Take the final generation of all the treatments.\n",
    "2. Select the best set of solutions from all the final generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.10299750041157082, 0.5396698782151578, 0.6608695652173913, 0.0],\n",
       " [0.09958142712660678, 0.772687573987016, 0.6884057971014492, 0.0],\n",
       " [0.09873984318665308,\n",
       "  0.688981118336843,\n",
       "  0.9225806451612903,\n",
       "  0.192090395480226],\n",
       " [0.0915939211696852,\n",
       "  0.5201361891509115,\n",
       "  0.8497109826589595,\n",
       "  0.10365853658536583],\n",
       " [0.08738234913396675, 0.653748187881778, 0.712707182320442, 0.0],\n",
       " [0.07798260806583651,\n",
       "  0.4374363614005098,\n",
       "  0.9435483870967742,\n",
       "  0.26875000000000004],\n",
       " [0.07765335322416529, 0.5706053874436364, 0.8695652173913043, 0.0],\n",
       " [0.06966259780901314,\n",
       "  0.5721201437854408,\n",
       "  0.9736842105263158,\n",
       "  0.22916666666666663],\n",
       " [0.06454575880596088,\n",
       "  0.5903604706736836,\n",
       "  0.7592592592592593,\n",
       "  0.0888888888888889],\n",
       " [0.055610178628247874,\n",
       "  0.7660031282960829,\n",
       "  0.9285714285714286,\n",
       "  0.5357142857142857]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_reference(problem, *fronts):\n",
    "  \"\"\"\n",
    "  Make a reference set comparing all the fronts.\n",
    "  Here the comparison we use is bdom. It can\n",
    "  be altered to use cdom as well\n",
    "  \"\"\"\n",
    "  retain_size = len(fronts[0])\n",
    "  reference = []\n",
    "  for front in fronts:\n",
    "    reference+=front\n",
    "\n",
    "  def bdom(one, two):\n",
    "    \"\"\"\n",
    "    Return True if 'one' dominates 'two'\n",
    "    else return False\n",
    "    :param one - [pt1_obj1, pt1_obj2, pt1_obj3, pt1_obj4]\n",
    "    :param two - [pt2_obj1, pt2_obj2, pt2_obj3, pt2_obj4]\n",
    "    \"\"\"\n",
    "    dominates = False\n",
    "    for i, obj in enumerate(problem.objectives):\n",
    "      gt, lt = pom3_ga.gt, pom3_ga.lt\n",
    "      better = lt if obj.do_minimize else gt\n",
    "      # TODO 3: Use the varaibles declared above to check if one dominates two\n",
    "    return dominates\n",
    "  \n",
    "  def fitness(one, dom):\n",
    "    return len([1 for another in reference if dom(one, another)])\n",
    "  \n",
    "  fitnesses = []\n",
    "  for point in reference:\n",
    "    fitnesses.append((fitness(point, bdom), point))\n",
    "  reference = [tup[1] for tup in sorted(fitnesses, reverse=True)]\n",
    "  return reference[:retain_size]\n",
    "    \n",
    "make_reference(problem, tests[5][0], tests[10][0], tests[50][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread\n",
    "\n",
    "Calculating spread: \n",
    "\n",
    "<img width=300 src=\"http://mechanicaldesign.asmedigitalcollection.asme.org/data/Journals/JMDEDB/27927/022006jmd3.jpeg\">\n",
    "\n",
    "- Consider the population of final gen(P) and the Pareto Frontier(R).\n",
    "- Find the distances between the first point of P and first point of R(_d<sub>f</sub>_) and last point of P and last point of R(_d<sub>l</sub>_)\n",
    "- Find the distance between all points and their nearest neighbor _d<sub>i</sub>_ and\n",
    "  their nearest neighbor\n",
    "  - Then:\n",
    "  \n",
    "<img width=300 src=\"https://raw.githubusercontent.com/txt/ase16/master/img/spreadcalc.png\">\n",
    "\n",
    "- If all data is maximally spread, then all distances _d<sub>i</sub>_ are near mean d\n",
    "which would make _&Delta;=0_ ish.\n",
    "\n",
    "Note that _less_ the spread of each point to its neighbor, the _better_\n",
    "since this means the optimiser is offering options across more of the frontier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.303346687087\n",
      "0.468658704171\n",
      "0.408935028174\n"
     ]
    }
   ],
   "source": [
    "def eucledian(one, two):\n",
    "  \"\"\"\n",
    "  Compute Eucledian Distance between\n",
    "  2 vectors. We assume the input vectors\n",
    "  are normalized.\n",
    "  :param one: Vector 1\n",
    "  :param two: Vector 2\n",
    "  :return:\n",
    "  \"\"\"\n",
    "  # TODO 4: Code up the eucledian distance. https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "  #dist = 0\n",
    "  return (sum([(o-t)**2 for o,t in zip(one, two)]) / len(one))**0.5\n",
    "  #return dist\n",
    "\n",
    "def sort_solutions(solutions):\n",
    "  \"\"\"\n",
    "  Sort a list of list before computing spread\n",
    "  \"\"\"\n",
    "  def sorter(lst):\n",
    "    m = len(lst)\n",
    "    weights = reversed([10 ** i for i in xrange(m)])\n",
    "    return sum([element * weight for element, weight in zip(lst, weights)])\n",
    "  return sorted(solutions, key=sorter)\n",
    "\n",
    "\n",
    "def closest(one, many):\n",
    "  min_dist = sys.maxint\n",
    "  closest_point = None\n",
    "  for this in many:\n",
    "    dist = eucledian(this, one)\n",
    "    if dist < min_dist:\n",
    "      min_dist = dist\n",
    "      closest_point = this\n",
    "  return min_dist, closest_point\n",
    "\n",
    "def spread(obtained, ideals):\n",
    "  \"\"\"\n",
    "  Calculate the spread (a.k.a diversity)\n",
    "  for a set of solutions\n",
    "  \"\"\"\n",
    "  s_obtained = sort_solutions(obtained)\n",
    "  s_ideals = sort_solutions(ideals)\n",
    "  d_f = closest(s_ideals[0], s_obtained)[0]\n",
    "  d_l = closest(s_ideals[-1], s_obtained)[0]\n",
    "  n = len(s_ideals)\n",
    "  distances = []\n",
    "  for i in range(len(s_obtained)-1):\n",
    "    distances.append(eucledian(s_obtained[i], s_obtained[i+1]))\n",
    "  d_bar = sum(distances)/len(distances)\n",
    "  # TODO 5: Compute the value of spread using the definition defined in the previous cell.\n",
    "  d_sum = sum([abs(d_i - d_bar) for d_i in distances])\n",
    "  delta = (d_f + d_l + d_sum) / (d_f + d_l + (n-1)*d_bar)\n",
    "  return delta\n",
    "\n",
    "\n",
    "ref = make_reference(problem, tests[5][0], tests[10][0], tests[50][0])\n",
    "\n",
    "print(spread(tests[5][0], ref))\n",
    "print(spread(tests[10][0], ref))\n",
    "print(spread(tests[50][0], ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IGD = inter-generational distance; i.e. how good are you compared to the _best known_?\n",
    "\n",
    "- Find a _reference set_ (the best possible solutions)\n",
    "- For each optimizer\n",
    "      - For each item in its final Pareto frontier\n",
    "      - Find the nearest item in the reference set and compute the distance to it.\n",
    "      - Take the mean of all the distances. This is IGD for the optimizer\n",
    "\n",
    "Note that the _less_ the mean IGD, the _better_ the optimizer since\n",
    "this means its solutions are closest to the best of the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0583028727565\n",
      "0.0170606374943\n",
      "0.0673803419663\n"
     ]
    }
   ],
   "source": [
    "def igd(obtained, ideals):\n",
    "  \"\"\"\n",
    "  Compute the IGD for a\n",
    "  set of solutions\n",
    "  :param obtained: Obtained pareto front\n",
    "  :param ideals: Ideal pareto front\n",
    "  :return:\n",
    "  \"\"\"\n",
    "  # TODO 6: Compute the value of IGD using the definition defined in the previous cell.\n",
    "  igd_val = sum([closest(ideal, obtained)[0] for ideal in ideals]) / len(ideals)\n",
    "  return igd_val\n",
    "#   igd_val = 0\n",
    "#   return igd_val\n",
    "\n",
    "ref = make_reference(problem, tests[5][0], tests[10][0], tests[50][0])\n",
    "\n",
    "print(igd(tests[5][0], ref))\n",
    "print(igd(tests[10][0], ref))\n",
    "print(igd(tests[50][0], ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** IGD ***\n",
      "rank ,                   name ,    med   ,  iqr \n",
      "----------------------------------------------------\n",
      "1 ,                 gens_0 ,    3 ,    1 \n",
      "2 ,                 gens_5 ,    4 ,    2 \n",
      "2 ,                gens_10 ,    5 ,    2 \n",
      "3 ,                gens_50 ,    8 ,    2 \n",
      "\n",
      "*** Spread ***\n",
      "rank ,                   name ,    med   ,  iqr \n",
      "----------------------------------------------------\n",
      "1 ,                 gens_0 ,   34 ,    9 \n",
      "2 ,                 gens_5 ,   41 ,   21 \n",
      "2 ,                gens_10 ,   45 ,    9 \n",
      "3 ,                gens_50 ,   53 ,    9 \n"
     ]
    }
   ],
   "source": [
    "import sk\n",
    "sk = reload(sk)\n",
    "\n",
    "def format_for_sk(problem, data, measure):\n",
    "  \"\"\"\n",
    "  Convert the experiment data into the format\n",
    "  required for sk.py and computet the desired\n",
    "  'measure' for all the data.\n",
    "  \"\"\"\n",
    "  gens = data.keys()\n",
    "  reps = len(data[gens[0]])\n",
    "  measured = {gen:[\"gens_%d\"%gen] for gen in gens}\n",
    "  for i in range(reps):\n",
    "    ref_args = [data[gen][i] for gen in gens]\n",
    "    ref = make_reference(problem, *ref_args)\n",
    "    for gen in gens:\n",
    "      measured[gen].append(measure(data[gen][i], ref))\n",
    "  return measured\n",
    "\n",
    "def report(problem, tests, measure):\n",
    "  measured = format_for_sk(problem, tests, measure).values()\n",
    "  sk.rdivDemo(measured)\n",
    "    \n",
    "print(\"*** IGD ***\")\n",
    "report(problem, tests, igd)\n",
    "print(\"\\n*** Spread ***\")\n",
    "report(problem, tests, spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
